{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dd4a7ec"
      },
      "source": [
        "### 1 - Importing The Libraries"
      ],
      "id": "2dd4a7ec"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbbb1b75"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.regnet import RegNetX002\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "dbbb1b75"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90c67747"
      },
      "source": [
        "### 2 - Importing The Datasets"
      ],
      "id": "90c67747"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48481d17"
      },
      "outputs": [],
      "source": [
        "print(\"Dataset is creating...\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#The path of the datasets\n",
        "data_dir = '/content/drive/MyDrive/Education/MSc/GTSRB'\n",
        "train_path = '/content/drive/MyDrive/Education/MSc/GTSRB/Train'\n",
        "test_path = '/content/drive/MyDrive/Education/MSc/GTSRB/Test/'\n",
        "\n",
        "folders = os.listdir(train_path)\n",
        "samples_dict = {}\n",
        "\n",
        "for folder in folders:\n",
        "    images_in_folder = os.listdir(train_path + '/' + folder)\n",
        "    samples_dict[folder] = len(images_in_folder)\n",
        "\n",
        "image_data = []\n",
        "image_labels = []\n",
        "print(\"Done!\")"
      ],
      "id": "48481d17"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d809a08"
      },
      "source": [
        "### 3 - Converting The Images to 32x32 Size"
      ],
      "id": "5d809a08"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b296baf1"
      },
      "outputs": [],
      "source": [
        "print(\"Images are converting...\")\n",
        "class_num = len(os.listdir(train_path))\n",
        "for i in range(class_num):\n",
        "    path = train_path +'/'+ str(i)\n",
        "    images = os.listdir(path)\n",
        "\n",
        "    for img in images:\n",
        "        try:\n",
        "            image = cv2.imread(path + '/' + img)\n",
        "            image_fromarray = Image.fromarray(image, 'RGB')\n",
        "            resize_image = image_fromarray.resize((32, 32))\n",
        "            image_data.append(np.array(resize_image))\n",
        "            image_labels.append(i)\n",
        "        except:\n",
        "            print(\"Error in \" + img)\n",
        "print(\"Done!\")"
      ],
      "id": "b296baf1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b990080"
      },
      "source": [
        "### 4 - Creating The Array of The Data and Labels"
      ],
      "id": "9b990080"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6025c4a4"
      },
      "outputs": [],
      "source": [
        "print(\"The Array of The Data and Labels are creating...\")\n",
        "image_data = np.array(image_data)\n",
        "image_labels = np.array(image_labels)\n",
        "print(image_data.shape, image_labels.shape)\n",
        "print(\"Done!\")"
      ],
      "id": "6025c4a4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bf8d663"
      },
      "source": [
        "### 5 - Preparing The Dataset"
      ],
      "id": "6bf8d663"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5925bf3"
      },
      "outputs": [],
      "source": [
        "print(\"The Dataset is Preparing...\")\n",
        "#The dataset is split into training data and test data.\n",
        "x_train, x_test, y_train, y_test = train_test_split(image_data, image_labels, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "print(\"Training and test dataset information (# of images, image dimensions): \")\n",
        "print(\"x_train :\", x_train.shape)\n",
        "print(\"y_train :\", y_train.shape)\n",
        "print(\"x_test :\", x_test.shape)\n",
        "print(\"y_test :\", y_test.shape)\n",
        "\n",
        "#Dataset normalization\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "\n",
        "#Dataset One-Hot Encoding\n",
        "y_train = to_categorical(y_train, 43)\n",
        "y_test = to_categorical(y_test, 43)\n",
        "print(\"Done!\")"
      ],
      "id": "c5925bf3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fc8b42e"
      },
      "source": [
        "### 6 - Defining The Number of Epochs"
      ],
      "id": "7fc8b42e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c5cf281"
      },
      "outputs": [],
      "source": [
        "epoch_number=10"
      ],
      "id": "6c5cf281"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b022be99"
      },
      "source": [
        "### 7 - Run The Corresponding Cell to Run Related Neural Networks."
      ],
      "id": "b022be99"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38a3a34d"
      },
      "source": [
        "#### a) KolNet Model"
      ],
      "id": "38a3a34d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85b3003f"
      },
      "outputs": [],
      "source": [
        "print(\"The Model is Creating...\")\n",
        "#Create a Neural Network Model\n",
        "model = Sequential()\n",
        "\n",
        "#Convolutional Layer\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#Convolutional Layer\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#Convolutional Layer\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#Dense Layer\n",
        "model.add(Flatten())#Conversion of inputs into a single vector\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "#Output Layer\n",
        "model.add(Dense(class_num, activation='softmax'))\n",
        "\n",
        "#Compiling The Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Training\n",
        "history=model.fit(x_train, y_train, epochs=epoch_number, validation_data=(x_test, y_test), batch_size=64)\n",
        "\n",
        "#Measuring The Accuracy of The Model With The Test Data\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "print(\"Done!\")"
      ],
      "id": "85b3003f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31c6ed62"
      },
      "source": [
        "#### b) EfficientNet Model"
      ],
      "id": "31c6ed62"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de53f503"
      },
      "outputs": [],
      "source": [
        "model = EfficientNetB0(weights=None, input_shape=(32, 32, 3), classes=43)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, batch_size=64, epochs=epoch_number, validation_data=(x_test, y_test))"
      ],
      "id": "de53f503"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64e2f866"
      },
      "source": [
        "#### c) ResNet Model"
      ],
      "id": "64e2f866"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8f130b6a"
      },
      "outputs": [],
      "source": [
        "model = ResNet50(weights=None, input_shape=(32, 32, 3), classes=43)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, batch_size=64, epochs=epoch_number, validation_data=(x_test, y_test))"
      ],
      "id": "8f130b6a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e1c2670"
      },
      "source": [
        "### 8 - Accuracy of The Model and Saving the Model"
      ],
      "id": "0e1c2670"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b85e004a"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(x_test)\n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "accuracy = np.sum(predictions==y_true)/len(y_true)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "file_name = input(\"Enter the name of the data to save: \")\n",
        "model.save(file_name + '.h5')"
      ],
      "id": "b85e004a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88c8fb14"
      },
      "source": [
        "### 9 - Visualizing the result"
      ],
      "id": "88c8fb14"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5df0adcd"
      },
      "outputs": [],
      "source": [
        "epochs_range = range(epoch_number)\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "id": "5df0adcd"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}